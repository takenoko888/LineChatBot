"""
Ultimate System Test - ç©¶æ¥µã®ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ
"""
import asyncio
import logging
import sys
import os
from datetime import datetime

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ãƒ†ã‚¹ãƒˆç”¨ã«ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®š
os.environ['SKIP_CONFIG_VALIDATION'] = 'true'
os.environ['GEMINI_API_KEY'] = 'test_key_for_mock'
os.environ['MOCK_MODE'] = 'true'

async def test_core_functionality():
    """ã‚³ã‚¢æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
    logger.info("ğŸ§ª ã‚³ã‚¢æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹")

    try:
        # 1. ã‚µãƒ¼ãƒ“ã‚¹çµ±åˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®ç›´æ¥ãƒ†ã‚¹ãƒˆ
        from services.service_integration_manager import service_integration_manager

        # åˆ©ç”¨å¯èƒ½ãªã‚µãƒ¼ãƒ“ã‚¹ã‚’ç¢ºèª
        available_services = service_integration_manager.get_available_services()

        if available_services:
            logger.info(f"âœ… ã‚µãƒ¼ãƒ“ã‚¹çµ±åˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼å‹•ä½œç¢ºèª: {len(available_services)}å€‹ã®ã‚µãƒ¼ãƒ“ã‚¹")
        else:
            logger.warning("âš ï¸ åˆ©ç”¨å¯èƒ½ãªã‚µãƒ¼ãƒ“ã‚¹ãŒã‚ã‚Šã¾ã›ã‚“")

        # 2. ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆãƒ«ãƒ¼ã‚¿ãƒ¼ã®ç›´æ¥ãƒ†ã‚¹ãƒˆ
        from services.context_aware_router import context_aware_router

        # ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆåˆ†æã®ãƒ†ã‚¹ãƒˆ
        test_queries = [
            "ä»Šæ—¥ã®å¤©æ°—ã‚’æ•™ãˆã¦",
            "æ¯æœ8æ™‚ã«èµ·ã“ã—ã¦",
            "ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ¤œç´¢ã—ã¦"
        ]

        for query in test_queries:
            try:
                routing_decision = context_aware_router.analyze_and_route_sync(query)
                logger.info(f"âœ… ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆåˆ†æ: {query[:15]}... â†’ {routing_decision.selected_service}")
            except Exception as e:
                logger.warning(f"âš ï¸ ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆåˆ†æã‚¨ãƒ©ãƒ¼: {query[:15]}... - {str(e)}")

        # 3. æŸ”è»ŸAIã‚µãƒ¼ãƒ“ã‚¹ã®ç›´æ¥ãƒ†ã‚¹ãƒˆ
        from services.flexible_ai_service import flexible_ai_service

        try:
            response = flexible_ai_service.generate_flexible_response_sync("ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª")
            logger.info(f"âœ… æŸ”è»ŸAIã‚µãƒ¼ãƒ“ã‚¹: {len(response)}æ–‡å­—ã®å¿œç­”ç”Ÿæˆ")
        except Exception as e:
            logger.warning(f"âš ï¸ æŸ”è»ŸAIã‚µãƒ¼ãƒ“ã‚¹ã‚¨ãƒ©ãƒ¼: {str(e)}")

        return True

    except Exception as e:
        logger.error(f"âŒ ã‚³ã‚¢æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆå¤±æ•—: {str(e)}")
        return False

async def test_mock_responses():
    """ãƒ¢ãƒƒã‚¯å¿œç­”ãƒ†ã‚¹ãƒˆ"""
    logger.info("ğŸ¤– ãƒ¢ãƒƒã‚¯å¿œç­”ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹")

    try:
        from services.flexible_ai_service import flexible_ai_service
        from services.context_aware_router import context_aware_router

        # AIã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ¢ãƒƒã‚¯å¿œç­”ãƒ†ã‚¹ãƒˆ
        test_cases = [
            ("å¤©æ°—ã‚¯ã‚¨ãƒª", "ä»Šæ—¥ã®å¤©æ°—ã‚’æ•™ãˆã¦"),
            ("é€šçŸ¥ã‚¯ã‚¨ãƒª", "æ¯æœ8æ™‚ã«èµ·ã“ã—ã¦"),
            ("æ¤œç´¢ã‚¯ã‚¨ãƒª", "ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ¤œç´¢ã—ã¦"),
            ("ä¸€èˆ¬ã‚¯ã‚¨ãƒª", "ã“ã‚“ã«ã¡ã¯")
        ]

        for name, query in test_cases:
            try:
                # AIå¿œç­”ãƒ†ã‚¹ãƒˆ
                ai_response = flexible_ai_service.generate_flexible_response_sync(query)
                if ai_response and len(ai_response) > 0:
                    logger.info(f"  âœ… {name}: AIå¿œç­” {len(ai_response)}æ–‡å­—")
                else:
                    logger.warning(f"  âš ï¸ {name}: AIå¿œç­”ãªã—")

                # ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆåˆ†æãƒ†ã‚¹ãƒˆ
                routing_decision = context_aware_router.analyze_and_route_sync(query)
                if routing_decision:
                    logger.info(f"  âœ… {name}: ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆåˆ†æ {routing_decision.selected_service}")
                else:
                    logger.warning(f"  âš ï¸ {name}: ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆåˆ†æãªã—")

            except Exception as e:
                logger.warning(f"  âš ï¸ {name}: ã‚¨ãƒ©ãƒ¼ - {str(e)}")

        return True

    except Exception as e:
        logger.error(f"âŒ ãƒ¢ãƒƒã‚¯å¿œç­”ãƒ†ã‚¹ãƒˆå¤±æ•—: {str(e)}")
        return False

async def test_system_initialization():
    """ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ"""
    logger.info("ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹")

    try:
        from services.integrated_service_manager import integrated_service_manager

        # ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã®ç¢ºèª
        system_status = integrated_service_manager.get_system_status()

        logger.info("âœ… çµ±åˆã‚µãƒ¼ãƒ“ã‚¹ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–ç¢ºèª")
        logger.info(f"   åˆæœŸåŒ–çŠ¶æ…‹: {system_status.get('initialized', False)}")
        logger.info(f"   ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰: {system_status.get('mock_mode', False)}")
        logger.info(f"   åˆ©ç”¨å¯èƒ½ã‚µãƒ¼ãƒ“ã‚¹æ•°: {len(system_status.get('available_services', []))}")

        # çµ±è¨ˆæƒ…å ±
        user_stats = integrated_service_manager.get_user_statistics("test_user")
        logger.info("âœ… ãƒ¦ãƒ¼ã‚¶ãƒ¼çµ±è¨ˆæ©Ÿèƒ½ç¢ºèª")

        return True

    except Exception as e:
        logger.error(f"âŒ ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆå¤±æ•—: {str(e)}")
        return False

async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    logger.info("ğŸš€ ç©¶æ¥µã®ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹")

    tests = [
        ("ã‚³ã‚¢æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ", test_core_functionality),
        ("ãƒ¢ãƒƒã‚¯å¿œç­”ãƒ†ã‚¹ãƒˆ", test_mock_responses),
        ("ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ", test_system_initialization)
    ]

    results = []

    for test_name, test_func in tests:
        logger.info(f"\nğŸ“‹ {test_name} ã‚’å®Ÿè¡Œä¸­...")
        try:
            result = await test_func()
            results.append((test_name, result))
            status = "âœ…" if result else "âŒ"
            logger.info(f"  {status} {test_name} å®Œäº†")
        except Exception as e:
            logger.error(f"  âŒ {test_name} ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
            results.append((test_name, False))

    # çµæœã‚µãƒãƒªãƒ¼
    successful_tests = len([r for r in results if r[1]])
    total_tests = len(results)
    success_rate = successful_tests / total_tests if total_tests > 0 else 0

    print("\n" + "="*60)
    print("ğŸ“Š ç©¶æ¥µã®ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ ãƒ¬ãƒãƒ¼ãƒˆ")
    print("="*60)
    print(f"ç·ãƒ†ã‚¹ãƒˆæ•°: {total_tests}")
    print(f"æˆåŠŸãƒ†ã‚¹ãƒˆæ•°: {successful_tests}")
    print(f"å¤±æ•—ãƒ†ã‚¹ãƒˆæ•°: {total_tests - successful_tests}")
    print(f"æˆåŠŸç‡: {success_rate:.1%}")
    print(f"ãƒ†ã‚¹ãƒˆå®Œäº†æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # è©³ç´°ãªãƒ†ã‚¹ãƒˆçµæœ
    print("\nğŸ“‹ ãƒ†ã‚¹ãƒˆçµæœè©³ç´°:")
    for test_name, success in results:
        status = "âœ…" if success else "âŒ"
        print(f"  {status} {test_name}")

    # è©•ä¾¡
    if success_rate >= 0.8:
        print("\nğŸ‰ ã‚·ã‚¹ãƒ†ãƒ ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ï¼")
        print("âœ… ã™ã¹ã¦ã®ä¸»è¦æ©Ÿèƒ½ãŒå‹•ä½œç¢ºèªæ¸ˆã¿")
        return True
    elif success_rate >= 0.5:
        print("\nâš ï¸  ã‚·ã‚¹ãƒ†ãƒ ã¯éƒ¨åˆ†çš„ã«å‹•ä½œã—ã¦ã„ã¾ã™ãŒã€æ”¹å–„ãŒå¿…è¦ã§ã™ã€‚")
        return True
    else:
        print("\nâŒ ã‚·ã‚¹ãƒ†ãƒ ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ä¿®æ­£ãŒå¿…è¦ã§ã™ã€‚")
        return False

def main_sync():
    """åŒæœŸç‰ˆãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    logger.info("ğŸš€ ç©¶æ¥µã®ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹")

    tests = [
        ("ã‚³ã‚¢æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ", test_core_functionality),
        ("ãƒ¢ãƒƒã‚¯å¿œç­”ãƒ†ã‚¹ãƒˆ", test_mock_responses),
        ("ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ", test_system_initialization)
    ]

    results = []

    for test_name, test_func in tests:
        logger.info(f"\nğŸ“‹ {test_name} ã‚’å®Ÿè¡Œä¸­...")
        try:
            result = test_func()  
            results.append((test_name, result))
            status = "âœ…" if result else "âŒ"
            logger.info(f"  {status} {test_name} å®Œäº†")
        except Exception as e:
            logger.error(f"  âŒ {test_name} ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
            results.append((test_name, False))

    # çµæœã‚µãƒãƒªãƒ¼
    successful_tests = len([r for r in results if r[1]])
    total_tests = len(results)
    success_rate = successful_tests / total_tests if total_tests > 0 else 0

    print("\n" + "="*60)
    print("ğŸ“Š ç©¶æ¥µã®ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ ãƒ¬ãƒãƒ¼ãƒˆ")
    print("="*60)
    print(f"ç·ãƒ†ã‚¹ãƒˆæ•°: {total_tests}")
    print(f"æˆåŠŸãƒ†ã‚¹ãƒˆæ•°: {successful_tests}")
    print(f"å¤±æ•—ãƒ†ã‚¹ãƒˆæ•°: {total_tests - successful_tests}")
    print(f"æˆåŠŸç‡: {success_rate:.1%}")
    print(f"ãƒ†ã‚¹ãƒˆå®Œäº†æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # è©³ç´°ãªãƒ†ã‚¹ãƒˆçµæœ
    print("\nğŸ“‹ ãƒ†ã‚¹ãƒˆçµæœè©³ç´°:")
    for test_name, success in results:
        status = "âœ…" if success else "âŒ"
        print(f"  {status} {test_name}")

    # è©•ä¾¡
    if success_rate >= 0.8:
        print("\nğŸ‰ ã‚·ã‚¹ãƒ†ãƒ ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ï¼")
        print("âœ… ã™ã¹ã¦ã®ä¸»è¦æ©Ÿèƒ½ãŒå‹•ä½œç¢ºèªæ¸ˆã¿")
        return True
    elif success_rate >= 0.5:
        print("\nâš ï¸  ã‚·ã‚¹ãƒ†ãƒ ã¯éƒ¨åˆ†çš„ã«å‹•ä½œã—ã¦ã„ã¾ã™ãŒã€æ”¹å–„ãŒå¿…è¦ã§ã™ã€‚")
        return True
    else:
        print("\nâŒ ã‚·ã‚¹ãƒ†ãƒ ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ä¿®æ­£ãŒå¿…è¦ã§ã™ã€‚")
        return False

if __name__ == "__main__":
    success = main_sync()
    logger.info(f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œå®Œäº†: {'æˆåŠŸ' if success else 'å¤±æ•—'}")
    sys.exit(0 if success else 1)
